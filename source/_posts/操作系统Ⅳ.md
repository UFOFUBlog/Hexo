---
title: 操作系统Ⅳ
top: false
cover: false
toc: true
mathjax: true
date: 2022-05-31 09:57:24
summary: 计算机存储体系Ⅰ
password:
tags:
  - 操作系统
categories:
---

## 序言

嘿嘿，想不到我又更新吧。

主要是最近看到一句话，说什么无用之用是为大用，想想也有点道理。

每个人在每个不同的时期是有不同的任务的，朝着目标前进当然无可厚非，但是如果脑子里只想着利益最大化，其他一切不管不顾，反而似乎有那么一点点的病态。

实不相瞒，高中的我好像就是这样的。

也许也是因为昨晚看了《釜山行》的结果。

《釜山行》大致讲的就是精致利己主义男主在经历一系列变故后发现了合作的力量，然后迷途知返的故事。

当然，作为对照就是有一个老油条，一心只想着自己的安危，踩在别人的生命上逃亡。

毫无疑问，最后他肯定是不得好死，但是我想如果没有这件事情，男主未来的样子差不多应该也是这样——别人的事管那么多干啥，自己小命最要紧。

作为旁观者，我们都能够很清楚的看到谁谁谁陷入了囚徒困境，明明合作收益大于对抗，但是却迷糊的摸不着边。

不过我也在想，现实中又有多少人，包括我自己，不知不觉中认为对抗才是对自己最有利的呢？

上面问题不好想，那就先缓缓。

总而言之，韩国片对于人物个性以及细腻情感的拿捏是真的厉害，反正米国是搞不出来的，兔子那就算了。

对了，本篇不是影评，本篇是技术文章。

最近折腾了三天的计算机存储体系，计组+OS的组合拳打得我满地找牙，一个左勾拳一个右勾拳，真的是，哎，一言难尽。

所以这次准备写个推文好好理一理存储体系里面的恩怨情仇。

因为是计组+OS的组合拳，所以“软硬兼施”，请接招。

## 正文

当我们买一台设备的时候，我们一般会考虑以下几个参数：

>CPU（不过大多数人看不明白），
>
>GPU（游戏党必备）
>
>内存大小（这个我懂），
>
>硬盘大小（外行可能不是很懂）
>
>价格（很重要很重要）
>
>其他杂项，比如分辨率，扬声器之类的。
>
>

这几个参数仔细看看，普通人大概最能理解的就是内存和价格了。

价格不必说，那这个“内存”到底是什么呢？

比如最近我爸想换手机，让我帮他看看，他给出的一个要求便是——“内存要大”。因为他不喜欢被总容量卡着然后被迫去删东西。

我爸所说的的“内存”和我们接下来要聊的“内存”应该是完全不一样的。

我爸理解的“内存大小”应该是：手机内能存的东西的大小，而不是现在手机常写的“运行内存”或者是我们所指的“内存”。

计算机除了计算，还有一个重要的功能便是存储信息。

这个存储系统比较复杂，我爸笼统的把它认为是“内存”，我们毕竟是“专业”的doge，所以要好好挖一挖这玩意的机理。

### 一. 存储体系架构

根据存储器的访存速度不同，我们大致可以把存储器分为三个部分：Cache，主存/内存，辅存/外存。

其中Cache的速度最快，可与CPU速度相匹配，所以通常放在CPU中。

主存速度稍慢，虽然不能永久保留信息，但是CPU可直接随机对其进行访问。

辅存可以永久保留的信息，但是要在调入主存后才可访问。

这时候有人可能会问，既然Cache那么快，那为什么不全都用Cache作为内存和辅存呢？

因为贵啊！

如果有一个玩意又便宜又快，那早就把其他竞争者挤掉了。

而且除了价格的因素外，还因为构造机理（Cache和主存用RAM，即随机存储器，辅存用ROM，即只读存储器）不同，Cache和主存的内容在计算机关机断电后就会消失，但是硬盘的内容却不会。

对于这种断电后内容会丢的情况，我们把它称为“易失性”，反之就是“非易失性”。

之前提到，快的东西贵，慢的容量大，我想两个都要，咋整？

这时候就需要使用OS的一个层次架构的理念了，那就是：

>访存快的存储器作为慢的的高速缓存

就是说，A很快但是不够大，B很慢但是很大，我如果把B中的部分内容Copy到A上面，是不是就又快又大了呢？

不一定吧？

我咋知道B中的内容一定能在A里面的，万一不在那岂不是还要再调入内容，次数多了不是很费时间吗？

这时候就要运用著名的局部性原理了.

研究发现，程序在一定时间内访问的内容规模是相对稳定的。

比如我写了个循环，那用到的部分一段时间内都是循环体里面的，循环体外面的东西，如果它在外存里面（虚拟存储器专享），那我就暂时不用copy它了，先copy循环体里面的内容再说。

至此，我们的体系就出来了（先不管寄存器）：

>CPU
>
>Cache
>
>主存
>
>辅存

除CPU外，由上到下，速度依次下降，容量依次变大。上面都是下面的局部备份。这样就可以享受又快又大的完美体验了。~~不应该慢点好吗？~~

因为大多数人对“内存”念念不忘，所以我们先从内存开始。

同时这也是整个存储体系的核心，起着支柱作用（因为又快，容量也不小，所以操作空间就很足）。

### 二. 内存

#### 1. 物理架构

之前不是提到主存是用RAM构成的吗，Cache也是RAM构成的，为啥他俩有这么大差距？

其实RAM再细分的话有SRAM和DRAM两种。前者速度快，集成度低，功耗大，价格贵，后者取反。原理我们不聊，硬件的天空很广大，有兴趣的同学可以深挖一下。

我们对内存的 一个很大的需求就是要大，怎么大怎么来，所以显而易见，后者才能成为主存的构成。

因为DRAM是栅极电容构成的，然后又好像因为一些莫名其妙的原因（上课没认真听，忘了具体是啥了doge），发生了漏电现象，电漏完了（大概在2ms内漏完）数据就丢失了，所以这时候就需要补电。

好，那怎么补？

正说：我们采取固定时间全体刷新一次，此期间内停止读写。

反说：对每行（电容构成的是二维矩阵，有行有列）的刷新分散到各个工作周期，工作周期分为两部分，前半周期读写，后半周期刷新。

折中说：我们取时间间隔t=最大刷新周期/行数，每隔t产生一次刷新。

如果你是leader，你选哪一个？

信孔子，选中庸之道——折中说doge。

折中说也称异步刷新，从各项评估结果来看，它能避免CPU连续等待过长时间，减少刷新次数，从而提高整机工作效率。恭喜你，选对了。

为什么不采纳正说或者反说呢？

正说也叫集中刷新，那个刷新的固定时间，我们称为死区，死区不能访存。相当于定期有一点时间内存是不存在的，显然降低了计算机的效率。

反说也叫分散刷新，它没有死区，但是它加长了系统的存取周期，导致降低整机速度。

罗老师：我看一眼就看到了答案。

对了，因为DRAM芯片容量大，地址较多，所以为了减少地址引脚数，现在都采用了地址引脚复用技术，即“行，列地址用相同的引脚分先后两次输入”，从而使得引脚数减少一半。

恶心的题目会把这个当作隐藏条件恶心你。

好，讲完了内存的构造，我们接下来聊聊内存是怎么干活的。

#### 2，功能

毕竟内存的容量是有限的，那么内存就需要具备一个良好的分配+回收功能。

不然的话程序员就会很烦躁——每个程序都要花心思决定放内存哪里，这不是要人命吗？

其次，主存内部的进程要能够共享有些信息，比如一些公用的区域用来通信啥的，但是不能全共享出去，进程也是需要私密空间的。所以这时候就需要内存保护功能了，用来实现进程的“私有财产”神圣不可侵犯。

最后，欲望是无限的，需求是有限的，所以我们需要更大的内存，但是价格又不想太高，这时候虚拟存储就上场了。

这些功能我们一个一个来。首先从分配方式开始。

依据进程的总体是连续存放的，还是离散存放的，我们有两种管理方式。

##### Ⅰ. 连续存储管理

首先上场的选手是最原始的单一连续分配。

1）单一连续分配

它有系统区和用户区。

>系统区仅供OS，通常在低地址。
>
>用户区只有一个用户程序，独占所有用户空间

它的有优点：简单（我上我也行），无外部碎片并且无需进行内存保护——只有一个程序。

这个“外部碎片”是个啥玩意？

“碎片”指的就是不能被利用的部分。它分为“外部碎片”+“内部碎片”。

前者指的是两个分块之间的不能被利用的小块空间。后者则是系统给一个进程多分配而进程用不到的空间。

当然了，缺点也显而易见：只用于单用户，单进程，并且有内部碎片，存储器利用率极低。

简单归简单，但是不实用，我们得改进。

如果我有多个进程的需求，那么是不是让他们都像第一种方式跑就行了？

所以固定分区分配的想法就出来了。

2）固定分区分配

如果我提前把主存区分划分成多个块，怎么样？

如果每个块一样大，如何？大概长这样：

![](tup1.png)

那划分的依据是什么呢？有的进程很大，有的很小，小的太浪费，大的塞不进。所以不灵活。

那大小不等呢？大概长这样：

![](tup2.png)

这时候分区按照大小排队，并建立分区说明表	程序装入时检索表，找到合适的就分配；回收时，对应表项设置为“未分配”即可。

好像理想的情况下真不错，但是这种划分是定死的，就像一个冥顽不化的人，如果不做改变，是很难适应时代的。

所以，动态分区分配上场了。

3）动态分区分配

顾名思义，它是根据进程需要，动态分配适合的。它的分区大小，数目可变。

它刚开始效果很不错，但是后来实践发现其越用越不行。为啥越来越不行? 

我们可以把整个内存看作一个大冰块。

每次有进程来的时候就把冰块切一部分。

进程跑完了就把冰块和旁边的空闲冰块合并成一个大冰块。

大家可以想想，如果冰块切切合合，是不是会出现一些新的东西？

没错，大量的冰渣子。也就是上文提到的外部碎片。

这些冰渣子很多都派不上用场，但是会阻塞检索时的速率，所以后期这种算法就越用越糟糕了。比如下面这张图展现的那样：

![](tup3.jpg)

当然了，冰渣子也是可以重融再生的，我们用拼接技术，它可以使分散的小空闲区连成一个大的空闲区。

之前提到了检索，也就是内存决定给进程多大的块的策略。怎么检索也是一种学问。

目前有四种主流的方式：

>首次适应分配First Fit
>
>临近适应Next Fit
>
>最佳适应Best Fit
>
>最坏适应Worst FIt

对于FF来说，根据各个块的地址序号由小到大排列，进程来了谁行谁上。

可见，它是一种很简单的方式，后来测试发现它通常也是最快和最好的。

一句话点评：简洁就是美。

对于NF来说，它发现FF有个问题——第二个进程检索表格的内容的时候，会重新检索一遍第一个进程已经扫过的部分，如果这些部分存在大量外部碎片，那么是很影响效率的。

所以NF决定从上次查找结束的位置开始继续找。但是这样又会在尾部分裂多个小碎片。。。。而且测试发现其综合比前者差。。。。

一句话点评：没事别瞎改。

BF看这俩二货胡闹：为啥按照地址空间大小排序呢？为什么不按照块的大小呢？

我们按照空间大小排序，递增，第一个合适的就上。不就完美了？

但是后来测试发现：空间大小每次分配/合并后就会改变，从而分配链表就需要修改，反而效率受到了影响。而且每次分配的时候都是相近的块给予空间，这就导致外部碎片数量剧增。

实际效果来看，性能通常很差。

一句话点评：愚昧和无知不是生存的障碍，傲慢才是。

WF反BF之道而行之，我们递减，第一个合适就上，这样外部碎片就少很多了吧。

的确，因为毕竟是很大块给小块分配，剩余的那个块一般也不会小到哪里去，但是它会很快导致没有可用的大内存块，从而对于大容量的适配性非常差。

一句话点评：逆向思维值得称赞。

至此，四种主流想法都讨论完了。

感觉好像都不咋地啊，到底是哪里出问题了呢？

问题在于连续。

我们为什么要让进程一定连续的存储在一起呢？为什么不能离散的存储呢？

#所以，超级重要，超级实用的离散存储登上了舞台。

不过因为这是一个大头，得细细的讲，所以准备放到下一篇。



## 尾声

之前看到一句话，说：“其实技术框架，就是人类社会框架的数码映射”。

当时看的时候觉得这人讲的好像有点道理，plausible那种感觉。后来看完存储体系后，惊呼一声：原来是我之前太肤浅了。

其实当你看到存储器设计或者策略里面的“正说反说折中说”的时候，会突然觉得——这个我熟，罗老师讲过。

当你再看到设计理念中的管理层，执行层，被执行对象的时候，转念一看，这不就是人类社会的工作架构码？

当你再瞅到各种特权优先的时候，你会明白这是一种不公平但是却必要的方式。象棋中的弃车保帅，也差不多是同样的道理，比如卢沟桥事变的时候，日军第一炮就把司令部炸了，你说这仗接下来怎么打？

所以“人人都厌恶特权，人人都想成为特权”，是人性，也是现实。

我一直认为，一个人的能力应该是类似虚存的理论极大容量那般，是由指令的地址长度决定的，但是内存+外存的时代局限性把很多人困住了，所以能力从极大容量转变为了实际容量。

所以最近出现的那啥“有人出生就在罗马，有人出生就是牛马”，也就很好理解了。

最后，附上也许是曾曾曾孙辈的数学启蒙书：

![](tups.png)

## 未完待续



